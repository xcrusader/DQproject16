{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [1 Introduction](#1)\n",
    "- [2 Title](#2)\n",
    "- [3 Title](#3)\n",
    "- [4 Title](#4)\n",
    "- [5 Title](#5)\n",
    "- [6 Title](#6)\n",
    "- [7 Title](#7)\n",
    "- [8 Title](#8)\n",
    "- [9 Title](#9)\n",
    "- [10 Title](#10)\n",
    "- [11 Title](#11)\n",
    "- [12 Title](#12)\n",
    "- [13 Title](#13)\n",
    "- [14 Title](#14)\n",
    "- [15 Next Steps](#15)\n",
    "- [16 Conclusions](#21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spam e-mails are an annoyance and in some cases can becomes a security issue. It becomes a security issue when e-mail users actively attend to the links or the directions provided in the spam message.\n",
    "\n",
    "Identifying such messages can be a challenge especially because the system may be unaware of the difference between ham(valid) and spam messages. \n",
    "\n",
    "The rise of data science and machine learning has allowed to identify spam e-mails.\n",
    "The goal of this project is to use two such machine learning models namely, Naive Bayes Classification and Logistic Regression to identify whether an e-mail is spam or ham based on the contents of the Subject and Content section of an e-mail.\n",
    "- Subject section of an e-mail\n",
    "- Content section of an e-mail\n",
    "\n",
    "Besides this we will verify the effectiveness of each models based on measurements,such as accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instructions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "emails = pd.read_csv(\"spam_ham_dataset.csv\")\n",
    "emails.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Subject: neon retreat\\r\\nho ho ho , we ' re around to that most wonderful time of the year - - - neon leaders retreat time !\\r\\ni know that this time of year is extremely hectic , and that it ' s tough to think about anything past the holidays , but life does go on past the week of december 25 through january 1 , and that ' s what i ' d like you to think about for a minute .\\r\\non the calender that i handed out at the beginning of the fall semester , the retreat was scheduled for the weekend of january 5 - 6 . but because of a youth ministers conference that brad and dustin are connected with that week , we ' re going to change the date to the following weekend , january 12 - 13 . now comes the part you need to think about .\\r\\ni think we all agree that it ' s important for us to get together and have some time to recharge our batteries before we get to far into the spring semester , but it can be a lot of trouble and difficult for us to get away without kids , etc . so , brad came up with a potential alternative for how we can get together on that weekend , and then you can let me know which you prefer .\\r\\nthe first option would be to have a retreat similar to what we ' ve done the past several years . this year we could go to the heartland country inn ( www . . com ) outside of brenham . it ' s a nice place , where we ' d have a 13 - bedroom and a 5 - bedroom house side by side . it ' s in the country , real relaxing , but also close to brenham and only about one hour and 15 minutes from here . we can golf , shop in the antique and craft stores in brenham , eat dinner together at the ranch , and spend time with each other . we ' d meet on saturday , and then return on sunday morning , just like what we ' ve done in the past .\\r\\nthe second option would be to stay here in houston , have dinner together at a nice restaurant , and then have dessert and a time for visiting and recharging at one of our homes on that saturday evening . this might be easier , but the trade off would be that we wouldn ' t have as much time together . i ' ll let you decide .\\r\\nemail me back with what would be your preference , and of course if you ' re available on that weekend . the democratic process will prevail - - majority vote will rule ! let me hear from you as soon as possible , preferably by the end of the weekend . and if the vote doesn ' t go your way , no complaining allowed ( like i tend to do ! )\\r\\nhave a great weekend , great golf , great fishing , great shopping , or whatever makes you happy !\\r\\nbobby\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails['text'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lazy operator: https://stackoverflow.com/questions/2013124/regex-matching-up-to-the-first-occurrence-of-a-character\n",
    "#Splitting columns: Future consideration (https://stackoverflow.com/questions/14745022/how-to-split-a-dataframe-string-column-into-two-columns/21296915#21296915)\n",
    "\n",
    "emails[\"subjects\"] = emails[\"text\"].str.extract(\"Subject:(.*?)\\\\r\\\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails[\"contents\"]=emails[\"text\"].str.extract(\"(?s)\\\\r\\\\n(.*)\",expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ho ho ho , we ' re around to that most wonderful time of the year - - - neon leaders retreat time !\\r\\ni know that this time of year is extremely hectic , and that it ' s tough to think about anything past the holidays , but life does go on past the week of december 25 through january 1 , and that ' s what i ' d like you to think about for a minute .\\r\\non the calender that i handed out at the beginning of the fall semester , the retreat was scheduled for the weekend of january 5 - 6 . but because of a youth ministers conference that brad and dustin are connected with that week , we ' re going to change the date to the following weekend , january 12 - 13 . now comes the part you need to think about .\\r\\ni think we all agree that it ' s important for us to get together and have some time to recharge our batteries before we get to far into the spring semester , but it can be a lot of trouble and difficult for us to get away without kids , etc . so , brad came up with a potential alternative for how we can get together on that weekend , and then you can let me know which you prefer .\\r\\nthe first option would be to have a retreat similar to what we ' ve done the past several years . this year we could go to the heartland country inn ( www . . com ) outside of brenham . it ' s a nice place , where we ' d have a 13 - bedroom and a 5 - bedroom house side by side . it ' s in the country , real relaxing , but also close to brenham and only about one hour and 15 minutes from here . we can golf , shop in the antique and craft stores in brenham , eat dinner together at the ranch , and spend time with each other . we ' d meet on saturday , and then return on sunday morning , just like what we ' ve done in the past .\\r\\nthe second option would be to stay here in houston , have dinner together at a nice restaurant , and then have dessert and a time for visiting and recharging at one of our homes on that saturday evening . this might be easier , but the trade off would be that we wouldn ' t have as much time together . i ' ll let you decide .\\r\\nemail me back with what would be your preference , and of course if you ' re available on that weekend . the democratic process will prevail - - majority vote will rule ! let me hear from you as soon as possible , preferably by the end of the weekend . and if the vote doesn ' t go your way , no complaining allowed ( like i tend to do ! )\\r\\nhave a great weekend , great golf , great fishing , great shopping , or whatever makes you happy !\\r\\nbobby\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails['contents'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails.drop(columns=['Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "      <th>subjects</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>enron methanol ; meter # : 988291</td>\n",
       "      <td>this is a follow up to the note i gave you on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "      <td>hpl nom for january 9 , 2001</td>\n",
       "      <td>( see attached file : hplnol 09 . xls )\\r\\n- h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>neon retreat</td>\n",
       "      <td>ho ho ho , we ' re around to that most wonderf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "      <td>photoshop , windows , office . cheap . main t...</td>\n",
       "      <td>abasements darer prudently fortuitous undergon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "      <td>re : indian springs</td>\n",
       "      <td>this deal is to book the teco pvr revenue . it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  label_num  \\\n",
       "0   ham  Subject: enron methanol ; meter # : 988291\\r\\n...          0   \n",
       "1   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...          0   \n",
       "2   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...          0   \n",
       "3  spam  Subject: photoshop , windows , office . cheap ...          1   \n",
       "4   ham  Subject: re : indian springs\\r\\nthis deal is t...          0   \n",
       "\n",
       "                                            subjects  \\\n",
       "0                  enron methanol ; meter # : 988291   \n",
       "1                       hpl nom for january 9 , 2001   \n",
       "2                                       neon retreat   \n",
       "3   photoshop , windows , office . cheap . main t...   \n",
       "4                                re : indian springs   \n",
       "\n",
       "                                            contents  \n",
       "0  this is a follow up to the note i gave you on ...  \n",
       "1  ( see attached file : hplnol 09 . xls )\\r\\n- h...  \n",
       "2  ho ho ho , we ' re around to that most wonderf...  \n",
       "3  abasements darer prudently fortuitous undergon...  \n",
       "4  this deal is to book the teco pvr revenue . it...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "      <th>subjects</th>\n",
       "      <th>contents</th>\n",
       "      <th>clean_subject</th>\n",
       "      <th>clean_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>enron methanol ; meter # : 988291</td>\n",
       "      <td>this is a follow up to the note i gave you on ...</td>\n",
       "      <td>[enron, methanol, meter, 988291]</td>\n",
       "      <td>[this, is, a, follow, up, to, the, note, i, ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "      <td>hpl nom for january 9 , 2001</td>\n",
       "      <td>( see attached file : hplnol 09 . xls )\\r\\n- h...</td>\n",
       "      <td>[hpl, nom, for, january, 9, 2001]</td>\n",
       "      <td>[see, attached, file, hplnol, 09, xls, hplnol,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>neon retreat</td>\n",
       "      <td>ho ho ho , we ' re around to that most wonderf...</td>\n",
       "      <td>[neon, retreat]</td>\n",
       "      <td>[ho, ho, ho, we, re, around, to, that, most, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "      <td>photoshop , windows , office . cheap . main t...</td>\n",
       "      <td>abasements darer prudently fortuitous undergon...</td>\n",
       "      <td>[photoshop, windows, office, cheap, main, tren...</td>\n",
       "      <td>[abasements, darer, prudently, fortuitous, und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "      <td>re : indian springs</td>\n",
       "      <td>this deal is to book the teco pvr revenue . it...</td>\n",
       "      <td>[re, indian, springs]</td>\n",
       "      <td>[this, deal, is, to, book, the, teco, pvr, rev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: ehronline web address change\\r\\nthis ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ehronline web address change</td>\n",
       "      <td>this message is intended for ehronline users o...</td>\n",
       "      <td>[ehronline, web, address, change]</td>\n",
       "      <td>[this, message, is, intended, for, ehronline, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: spring savings certificate - take 30 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>spring savings certificate - take 30 % off</td>\n",
       "      <td>save 30 % when you use our customer appreciati...</td>\n",
       "      <td>[spring, savings, certificate, take, 30, off]</td>\n",
       "      <td>[save, 30, when, you, use, our, customer, appr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: looking for medication ? we ` re the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>looking for medication ? we ` re the best sou...</td>\n",
       "      <td>it is difficult to make our material condition...</td>\n",
       "      <td>[looking, for, medication, we, re, the, best, ...</td>\n",
       "      <td>[it, is, difficult, to, make, our, material, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: noms / actual flow for 2 / 26\\r\\nwe a...</td>\n",
       "      <td>0</td>\n",
       "      <td>noms / actual flow for 2 / 26</td>\n",
       "      <td>we agree\\r\\n- - - - - - - - - - - - - - - - - ...</td>\n",
       "      <td>[noms, actual, flow, for, 2, 26]</td>\n",
       "      <td>[we, agree, forwarded, by, melissa, jones, tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: nominations for oct . 21 - 23 , 2000\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>nominations for oct . 21 - 23 , 2000</td>\n",
       "      <td>( see attached file : hplnl 021 . xls )\\r\\n- h...</td>\n",
       "      <td>[nominations, for, oct, 21, 23, 2000]</td>\n",
       "      <td>[see, attached, file, hplnl, 021, xls, hplnl, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  label_num  \\\n",
       "0   ham  Subject: enron methanol ; meter # : 988291\\r\\n...          0   \n",
       "1   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...          0   \n",
       "2   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...          0   \n",
       "3  spam  Subject: photoshop , windows , office . cheap ...          1   \n",
       "4   ham  Subject: re : indian springs\\r\\nthis deal is t...          0   \n",
       "5   ham  Subject: ehronline web address change\\r\\nthis ...          0   \n",
       "6   ham  Subject: spring savings certificate - take 30 ...          0   \n",
       "7  spam  Subject: looking for medication ? we ` re the ...          1   \n",
       "8   ham  Subject: noms / actual flow for 2 / 26\\r\\nwe a...          0   \n",
       "9   ham  Subject: nominations for oct . 21 - 23 , 2000\\...          0   \n",
       "\n",
       "                                            subjects  \\\n",
       "0                  enron methanol ; meter # : 988291   \n",
       "1                       hpl nom for january 9 , 2001   \n",
       "2                                       neon retreat   \n",
       "3   photoshop , windows , office . cheap . main t...   \n",
       "4                                re : indian springs   \n",
       "5                       ehronline web address change   \n",
       "6         spring savings certificate - take 30 % off   \n",
       "7   looking for medication ? we ` re the best sou...   \n",
       "8                      noms / actual flow for 2 / 26   \n",
       "9               nominations for oct . 21 - 23 , 2000   \n",
       "\n",
       "                                            contents  \\\n",
       "0  this is a follow up to the note i gave you on ...   \n",
       "1  ( see attached file : hplnol 09 . xls )\\r\\n- h...   \n",
       "2  ho ho ho , we ' re around to that most wonderf...   \n",
       "3  abasements darer prudently fortuitous undergon...   \n",
       "4  this deal is to book the teco pvr revenue . it...   \n",
       "5  this message is intended for ehronline users o...   \n",
       "6  save 30 % when you use our customer appreciati...   \n",
       "7  it is difficult to make our material condition...   \n",
       "8  we agree\\r\\n- - - - - - - - - - - - - - - - - ...   \n",
       "9  ( see attached file : hplnl 021 . xls )\\r\\n- h...   \n",
       "\n",
       "                                       clean_subject  \\\n",
       "0                   [enron, methanol, meter, 988291]   \n",
       "1                  [hpl, nom, for, january, 9, 2001]   \n",
       "2                                    [neon, retreat]   \n",
       "3  [photoshop, windows, office, cheap, main, tren...   \n",
       "4                              [re, indian, springs]   \n",
       "5                  [ehronline, web, address, change]   \n",
       "6      [spring, savings, certificate, take, 30, off]   \n",
       "7  [looking, for, medication, we, re, the, best, ...   \n",
       "8                   [noms, actual, flow, for, 2, 26]   \n",
       "9              [nominations, for, oct, 21, 23, 2000]   \n",
       "\n",
       "                                       clean_content  \n",
       "0  [this, is, a, follow, up, to, the, note, i, ga...  \n",
       "1  [see, attached, file, hplnol, 09, xls, hplnol,...  \n",
       "2  [ho, ho, ho, we, re, around, to, that, most, w...  \n",
       "3  [abasements, darer, prudently, fortuitous, und...  \n",
       "4  [this, deal, is, to, book, the, teco, pvr, rev...  \n",
       "5  [this, message, is, intended, for, ehronline, ...  \n",
       "6  [save, 30, when, you, use, our, customer, appr...  \n",
       "7  [it, is, difficult, to, make, our, material, c...  \n",
       "8  [we, agree, forwarded, by, melissa, jones, tex...  \n",
       "9  [see, attached, file, hplnl, 021, xls, hplnl, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails['clean_subject']=emails['subjects'].str.replace(\"\\W\",\" \",regex=True).str.lower().str.split()\n",
    "emails['clean_content']=emails['contents'].str.replace(\"\\W\",\" \",regex=True).str.lower().str.split()\n",
    "emails.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ho',\n",
       " 'ho',\n",
       " 'ho',\n",
       " 'we',\n",
       " 're',\n",
       " 'around',\n",
       " 'to',\n",
       " 'that',\n",
       " 'most',\n",
       " 'wonderful',\n",
       " 'time',\n",
       " 'of',\n",
       " 'the',\n",
       " 'year',\n",
       " 'neon',\n",
       " 'leaders',\n",
       " 'retreat',\n",
       " 'time',\n",
       " 'i',\n",
       " 'know',\n",
       " 'that',\n",
       " 'this',\n",
       " 'time',\n",
       " 'of',\n",
       " 'year',\n",
       " 'is',\n",
       " 'extremely',\n",
       " 'hectic',\n",
       " 'and',\n",
       " 'that',\n",
       " 'it',\n",
       " 's',\n",
       " 'tough',\n",
       " 'to',\n",
       " 'think',\n",
       " 'about',\n",
       " 'anything',\n",
       " 'past',\n",
       " 'the',\n",
       " 'holidays',\n",
       " 'but',\n",
       " 'life',\n",
       " 'does',\n",
       " 'go',\n",
       " 'on',\n",
       " 'past',\n",
       " 'the',\n",
       " 'week',\n",
       " 'of',\n",
       " 'december',\n",
       " '25',\n",
       " 'through',\n",
       " 'january',\n",
       " '1',\n",
       " 'and',\n",
       " 'that',\n",
       " 's',\n",
       " 'what',\n",
       " 'i',\n",
       " 'd',\n",
       " 'like',\n",
       " 'you',\n",
       " 'to',\n",
       " 'think',\n",
       " 'about',\n",
       " 'for',\n",
       " 'a',\n",
       " 'minute',\n",
       " 'on',\n",
       " 'the',\n",
       " 'calender',\n",
       " 'that',\n",
       " 'i',\n",
       " 'handed',\n",
       " 'out',\n",
       " 'at',\n",
       " 'the',\n",
       " 'beginning',\n",
       " 'of',\n",
       " 'the',\n",
       " 'fall',\n",
       " 'semester',\n",
       " 'the',\n",
       " 'retreat',\n",
       " 'was',\n",
       " 'scheduled',\n",
       " 'for',\n",
       " 'the',\n",
       " 'weekend',\n",
       " 'of',\n",
       " 'january',\n",
       " '5',\n",
       " '6',\n",
       " 'but',\n",
       " 'because',\n",
       " 'of',\n",
       " 'a',\n",
       " 'youth',\n",
       " 'ministers',\n",
       " 'conference',\n",
       " 'that',\n",
       " 'brad',\n",
       " 'and',\n",
       " 'dustin',\n",
       " 'are',\n",
       " 'connected',\n",
       " 'with',\n",
       " 'that',\n",
       " 'week',\n",
       " 'we',\n",
       " 're',\n",
       " 'going',\n",
       " 'to',\n",
       " 'change',\n",
       " 'the',\n",
       " 'date',\n",
       " 'to',\n",
       " 'the',\n",
       " 'following',\n",
       " 'weekend',\n",
       " 'january',\n",
       " '12',\n",
       " '13',\n",
       " 'now',\n",
       " 'comes',\n",
       " 'the',\n",
       " 'part',\n",
       " 'you',\n",
       " 'need',\n",
       " 'to',\n",
       " 'think',\n",
       " 'about',\n",
       " 'i',\n",
       " 'think',\n",
       " 'we',\n",
       " 'all',\n",
       " 'agree',\n",
       " 'that',\n",
       " 'it',\n",
       " 's',\n",
       " 'important',\n",
       " 'for',\n",
       " 'us',\n",
       " 'to',\n",
       " 'get',\n",
       " 'together',\n",
       " 'and',\n",
       " 'have',\n",
       " 'some',\n",
       " 'time',\n",
       " 'to',\n",
       " 'recharge',\n",
       " 'our',\n",
       " 'batteries',\n",
       " 'before',\n",
       " 'we',\n",
       " 'get',\n",
       " 'to',\n",
       " 'far',\n",
       " 'into',\n",
       " 'the',\n",
       " 'spring',\n",
       " 'semester',\n",
       " 'but',\n",
       " 'it',\n",
       " 'can',\n",
       " 'be',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'trouble',\n",
       " 'and',\n",
       " 'difficult',\n",
       " 'for',\n",
       " 'us',\n",
       " 'to',\n",
       " 'get',\n",
       " 'away',\n",
       " 'without',\n",
       " 'kids',\n",
       " 'etc',\n",
       " 'so',\n",
       " 'brad',\n",
       " 'came',\n",
       " 'up',\n",
       " 'with',\n",
       " 'a',\n",
       " 'potential',\n",
       " 'alternative',\n",
       " 'for',\n",
       " 'how',\n",
       " 'we',\n",
       " 'can',\n",
       " 'get',\n",
       " 'together',\n",
       " 'on',\n",
       " 'that',\n",
       " 'weekend',\n",
       " 'and',\n",
       " 'then',\n",
       " 'you',\n",
       " 'can',\n",
       " 'let',\n",
       " 'me',\n",
       " 'know',\n",
       " 'which',\n",
       " 'you',\n",
       " 'prefer',\n",
       " 'the',\n",
       " 'first',\n",
       " 'option',\n",
       " 'would',\n",
       " 'be',\n",
       " 'to',\n",
       " 'have',\n",
       " 'a',\n",
       " 'retreat',\n",
       " 'similar',\n",
       " 'to',\n",
       " 'what',\n",
       " 'we',\n",
       " 've',\n",
       " 'done',\n",
       " 'the',\n",
       " 'past',\n",
       " 'several',\n",
       " 'years',\n",
       " 'this',\n",
       " 'year',\n",
       " 'we',\n",
       " 'could',\n",
       " 'go',\n",
       " 'to',\n",
       " 'the',\n",
       " 'heartland',\n",
       " 'country',\n",
       " 'inn',\n",
       " 'www',\n",
       " 'com',\n",
       " 'outside',\n",
       " 'of',\n",
       " 'brenham',\n",
       " 'it',\n",
       " 's',\n",
       " 'a',\n",
       " 'nice',\n",
       " 'place',\n",
       " 'where',\n",
       " 'we',\n",
       " 'd',\n",
       " 'have',\n",
       " 'a',\n",
       " '13',\n",
       " 'bedroom',\n",
       " 'and',\n",
       " 'a',\n",
       " '5',\n",
       " 'bedroom',\n",
       " 'house',\n",
       " 'side',\n",
       " 'by',\n",
       " 'side',\n",
       " 'it',\n",
       " 's',\n",
       " 'in',\n",
       " 'the',\n",
       " 'country',\n",
       " 'real',\n",
       " 'relaxing',\n",
       " 'but',\n",
       " 'also',\n",
       " 'close',\n",
       " 'to',\n",
       " 'brenham',\n",
       " 'and',\n",
       " 'only',\n",
       " 'about',\n",
       " 'one',\n",
       " 'hour',\n",
       " 'and',\n",
       " '15',\n",
       " 'minutes',\n",
       " 'from',\n",
       " 'here',\n",
       " 'we',\n",
       " 'can',\n",
       " 'golf',\n",
       " 'shop',\n",
       " 'in',\n",
       " 'the',\n",
       " 'antique',\n",
       " 'and',\n",
       " 'craft',\n",
       " 'stores',\n",
       " 'in',\n",
       " 'brenham',\n",
       " 'eat',\n",
       " 'dinner',\n",
       " 'together',\n",
       " 'at',\n",
       " 'the',\n",
       " 'ranch',\n",
       " 'and',\n",
       " 'spend',\n",
       " 'time',\n",
       " 'with',\n",
       " 'each',\n",
       " 'other',\n",
       " 'we',\n",
       " 'd',\n",
       " 'meet',\n",
       " 'on',\n",
       " 'saturday',\n",
       " 'and',\n",
       " 'then',\n",
       " 'return',\n",
       " 'on',\n",
       " 'sunday',\n",
       " 'morning',\n",
       " 'just',\n",
       " 'like',\n",
       " 'what',\n",
       " 'we',\n",
       " 've',\n",
       " 'done',\n",
       " 'in',\n",
       " 'the',\n",
       " 'past',\n",
       " 'the',\n",
       " 'second',\n",
       " 'option',\n",
       " 'would',\n",
       " 'be',\n",
       " 'to',\n",
       " 'stay',\n",
       " 'here',\n",
       " 'in',\n",
       " 'houston',\n",
       " 'have',\n",
       " 'dinner',\n",
       " 'together',\n",
       " 'at',\n",
       " 'a',\n",
       " 'nice',\n",
       " 'restaurant',\n",
       " 'and',\n",
       " 'then',\n",
       " 'have',\n",
       " 'dessert',\n",
       " 'and',\n",
       " 'a',\n",
       " 'time',\n",
       " 'for',\n",
       " 'visiting',\n",
       " 'and',\n",
       " 'recharging',\n",
       " 'at',\n",
       " 'one',\n",
       " 'of',\n",
       " 'our',\n",
       " 'homes',\n",
       " 'on',\n",
       " 'that',\n",
       " 'saturday',\n",
       " 'evening',\n",
       " 'this',\n",
       " 'might',\n",
       " 'be',\n",
       " 'easier',\n",
       " 'but',\n",
       " 'the',\n",
       " 'trade',\n",
       " 'off',\n",
       " 'would',\n",
       " 'be',\n",
       " 'that',\n",
       " 'we',\n",
       " 'wouldn',\n",
       " 't',\n",
       " 'have',\n",
       " 'as',\n",
       " 'much',\n",
       " 'time',\n",
       " 'together',\n",
       " 'i',\n",
       " 'll',\n",
       " 'let',\n",
       " 'you',\n",
       " 'decide',\n",
       " 'email',\n",
       " 'me',\n",
       " 'back',\n",
       " 'with',\n",
       " 'what',\n",
       " 'would',\n",
       " 'be',\n",
       " 'your',\n",
       " 'preference',\n",
       " 'and',\n",
       " 'of',\n",
       " 'course',\n",
       " 'if',\n",
       " 'you',\n",
       " 're',\n",
       " 'available',\n",
       " 'on',\n",
       " 'that',\n",
       " 'weekend',\n",
       " 'the',\n",
       " 'democratic',\n",
       " 'process',\n",
       " 'will',\n",
       " 'prevail',\n",
       " 'majority',\n",
       " 'vote',\n",
       " 'will',\n",
       " 'rule',\n",
       " 'let',\n",
       " 'me',\n",
       " 'hear',\n",
       " 'from',\n",
       " 'you',\n",
       " 'as',\n",
       " 'soon',\n",
       " 'as',\n",
       " 'possible',\n",
       " 'preferably',\n",
       " 'by',\n",
       " 'the',\n",
       " 'end',\n",
       " 'of',\n",
       " 'the',\n",
       " 'weekend',\n",
       " 'and',\n",
       " 'if',\n",
       " 'the',\n",
       " 'vote',\n",
       " 'doesn',\n",
       " 't',\n",
       " 'go',\n",
       " 'your',\n",
       " 'way',\n",
       " 'no',\n",
       " 'complaining',\n",
       " 'allowed',\n",
       " 'like',\n",
       " 'i',\n",
       " 'tend',\n",
       " 'to',\n",
       " 'do',\n",
       " 'have',\n",
       " 'a',\n",
       " 'great',\n",
       " 'weekend',\n",
       " 'great',\n",
       " 'golf',\n",
       " 'great',\n",
       " 'fishing',\n",
       " 'great',\n",
       " 'shopping',\n",
       " 'or',\n",
       " 'whatever',\n",
       " 'makes',\n",
       " 'you',\n",
       " 'happy',\n",
       " 'bobby']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails['clean_content'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate English stopwords\n",
    "from nltk.corpus import stopwords\n",
    "en_stops = set(stopwords.words('english'))\n",
    "\n",
    "def rem_stop_words(a_list):\n",
    "    no_stop_words=[]\n",
    "    for i in range(len(a_list)):\n",
    "        if a_list[i] not in en_stops:\n",
    "            no_stop_words.append(str(a_list[i]))\n",
    "    return no_stop_words\n",
    "\n",
    "emails['clean_subject']=emails['clean_subject'].apply(rem_stop_words)\n",
    "emails['clean_content']=emails['clean_content'].apply(rem_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "      <th>subjects</th>\n",
       "      <th>contents</th>\n",
       "      <th>clean_subject</th>\n",
       "      <th>clean_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>enron methanol ; meter # : 988291</td>\n",
       "      <td>this is a follow up to the note i gave you on ...</td>\n",
       "      <td>[enron, methanol, meter, 988291]</td>\n",
       "      <td>[follow, note, gave, monday, 4, 3, 00, prelimi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "      <td>hpl nom for january 9 , 2001</td>\n",
       "      <td>( see attached file : hplnol 09 . xls )\\r\\n- h...</td>\n",
       "      <td>[hpl, nom, january, 9, 2001]</td>\n",
       "      <td>[see, attached, file, hplnol, 09, xls, hplnol,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>neon retreat</td>\n",
       "      <td>ho ho ho , we ' re around to that most wonderf...</td>\n",
       "      <td>[neon, retreat]</td>\n",
       "      <td>[ho, ho, ho, around, wonderful, time, year, ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "      <td>photoshop , windows , office . cheap . main t...</td>\n",
       "      <td>abasements darer prudently fortuitous undergon...</td>\n",
       "      <td>[photoshop, windows, office, cheap, main, tren...</td>\n",
       "      <td>[abasements, darer, prudently, fortuitous, und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "      <td>re : indian springs</td>\n",
       "      <td>this deal is to book the teco pvr revenue . it...</td>\n",
       "      <td>[indian, springs]</td>\n",
       "      <td>[deal, book, teco, pvr, revenue, understanding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: ehronline web address change\\r\\nthis ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ehronline web address change</td>\n",
       "      <td>this message is intended for ehronline users o...</td>\n",
       "      <td>[ehronline, web, address, change]</td>\n",
       "      <td>[message, intended, ehronline, users, due, rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: spring savings certificate - take 30 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>spring savings certificate - take 30 % off</td>\n",
       "      <td>save 30 % when you use our customer appreciati...</td>\n",
       "      <td>[spring, savings, certificate, take, 30]</td>\n",
       "      <td>[save, 30, use, customer, appreciation, spring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: looking for medication ? we ` re the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>looking for medication ? we ` re the best sou...</td>\n",
       "      <td>it is difficult to make our material condition...</td>\n",
       "      <td>[looking, medication, best, source]</td>\n",
       "      <td>[difficult, make, material, condition, better,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: noms / actual flow for 2 / 26\\r\\nwe a...</td>\n",
       "      <td>0</td>\n",
       "      <td>noms / actual flow for 2 / 26</td>\n",
       "      <td>we agree\\r\\n- - - - - - - - - - - - - - - - - ...</td>\n",
       "      <td>[noms, actual, flow, 2, 26]</td>\n",
       "      <td>[agree, forwarded, melissa, jones, texas, util...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: nominations for oct . 21 - 23 , 2000\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>nominations for oct . 21 - 23 , 2000</td>\n",
       "      <td>( see attached file : hplnl 021 . xls )\\r\\n- h...</td>\n",
       "      <td>[nominations, oct, 21, 23, 2000]</td>\n",
       "      <td>[see, attached, file, hplnl, 021, xls, hplnl, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  label_num  \\\n",
       "0   ham  Subject: enron methanol ; meter # : 988291\\r\\n...          0   \n",
       "1   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...          0   \n",
       "2   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...          0   \n",
       "3  spam  Subject: photoshop , windows , office . cheap ...          1   \n",
       "4   ham  Subject: re : indian springs\\r\\nthis deal is t...          0   \n",
       "5   ham  Subject: ehronline web address change\\r\\nthis ...          0   \n",
       "6   ham  Subject: spring savings certificate - take 30 ...          0   \n",
       "7  spam  Subject: looking for medication ? we ` re the ...          1   \n",
       "8   ham  Subject: noms / actual flow for 2 / 26\\r\\nwe a...          0   \n",
       "9   ham  Subject: nominations for oct . 21 - 23 , 2000\\...          0   \n",
       "\n",
       "                                            subjects  \\\n",
       "0                  enron methanol ; meter # : 988291   \n",
       "1                       hpl nom for january 9 , 2001   \n",
       "2                                       neon retreat   \n",
       "3   photoshop , windows , office . cheap . main t...   \n",
       "4                                re : indian springs   \n",
       "5                       ehronline web address change   \n",
       "6         spring savings certificate - take 30 % off   \n",
       "7   looking for medication ? we ` re the best sou...   \n",
       "8                      noms / actual flow for 2 / 26   \n",
       "9               nominations for oct . 21 - 23 , 2000   \n",
       "\n",
       "                                            contents  \\\n",
       "0  this is a follow up to the note i gave you on ...   \n",
       "1  ( see attached file : hplnol 09 . xls )\\r\\n- h...   \n",
       "2  ho ho ho , we ' re around to that most wonderf...   \n",
       "3  abasements darer prudently fortuitous undergon...   \n",
       "4  this deal is to book the teco pvr revenue . it...   \n",
       "5  this message is intended for ehronline users o...   \n",
       "6  save 30 % when you use our customer appreciati...   \n",
       "7  it is difficult to make our material condition...   \n",
       "8  we agree\\r\\n- - - - - - - - - - - - - - - - - ...   \n",
       "9  ( see attached file : hplnl 021 . xls )\\r\\n- h...   \n",
       "\n",
       "                                       clean_subject  \\\n",
       "0                   [enron, methanol, meter, 988291]   \n",
       "1                       [hpl, nom, january, 9, 2001]   \n",
       "2                                    [neon, retreat]   \n",
       "3  [photoshop, windows, office, cheap, main, tren...   \n",
       "4                                  [indian, springs]   \n",
       "5                  [ehronline, web, address, change]   \n",
       "6           [spring, savings, certificate, take, 30]   \n",
       "7                [looking, medication, best, source]   \n",
       "8                        [noms, actual, flow, 2, 26]   \n",
       "9                   [nominations, oct, 21, 23, 2000]   \n",
       "\n",
       "                                       clean_content  \n",
       "0  [follow, note, gave, monday, 4, 3, 00, prelimi...  \n",
       "1  [see, attached, file, hplnol, 09, xls, hplnol,...  \n",
       "2  [ho, ho, ho, around, wonderful, time, year, ne...  \n",
       "3  [abasements, darer, prudently, fortuitous, und...  \n",
       "4  [deal, book, teco, pvr, revenue, understanding...  \n",
       "5  [message, intended, ehronline, users, due, rec...  \n",
       "6  [save, 30, use, customer, appreciation, spring...  \n",
       "7  [difficult, make, material, condition, better,...  \n",
       "8  [agree, forwarded, melissa, jones, texas, util...  \n",
       "9  [see, attached, file, hplnl, 021, xls, hplnl, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     71.01141\n",
       "spam    28.98859\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails['label'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oasis', 'line']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails['clean_subject'].iloc[78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ho',\n",
       " 'ho',\n",
       " 'ho',\n",
       " 'around',\n",
       " 'wonderful',\n",
       " 'time',\n",
       " 'year',\n",
       " 'neon',\n",
       " 'leaders',\n",
       " 'retreat',\n",
       " 'time',\n",
       " 'know',\n",
       " 'time',\n",
       " 'year',\n",
       " 'extremely',\n",
       " 'hectic',\n",
       " 'tough',\n",
       " 'think',\n",
       " 'anything',\n",
       " 'past',\n",
       " 'holidays',\n",
       " 'life',\n",
       " 'go',\n",
       " 'past',\n",
       " 'week',\n",
       " 'december',\n",
       " '25',\n",
       " 'january',\n",
       " '1',\n",
       " 'like',\n",
       " 'think',\n",
       " 'minute',\n",
       " 'calender',\n",
       " 'handed',\n",
       " 'beginning',\n",
       " 'fall',\n",
       " 'semester',\n",
       " 'retreat',\n",
       " 'scheduled',\n",
       " 'weekend',\n",
       " 'january',\n",
       " '5',\n",
       " '6',\n",
       " 'youth',\n",
       " 'ministers',\n",
       " 'conference',\n",
       " 'brad',\n",
       " 'dustin',\n",
       " 'connected',\n",
       " 'week',\n",
       " 'going',\n",
       " 'change',\n",
       " 'date',\n",
       " 'following',\n",
       " 'weekend',\n",
       " 'january',\n",
       " '12',\n",
       " '13',\n",
       " 'comes',\n",
       " 'part',\n",
       " 'need',\n",
       " 'think',\n",
       " 'think',\n",
       " 'agree',\n",
       " 'important',\n",
       " 'us',\n",
       " 'get',\n",
       " 'together',\n",
       " 'time',\n",
       " 'recharge',\n",
       " 'batteries',\n",
       " 'get',\n",
       " 'far',\n",
       " 'spring',\n",
       " 'semester',\n",
       " 'lot',\n",
       " 'trouble',\n",
       " 'difficult',\n",
       " 'us',\n",
       " 'get',\n",
       " 'away',\n",
       " 'without',\n",
       " 'kids',\n",
       " 'etc',\n",
       " 'brad',\n",
       " 'came',\n",
       " 'potential',\n",
       " 'alternative',\n",
       " 'get',\n",
       " 'together',\n",
       " 'weekend',\n",
       " 'let',\n",
       " 'know',\n",
       " 'prefer',\n",
       " 'first',\n",
       " 'option',\n",
       " 'would',\n",
       " 'retreat',\n",
       " 'similar',\n",
       " 'done',\n",
       " 'past',\n",
       " 'several',\n",
       " 'years',\n",
       " 'year',\n",
       " 'could',\n",
       " 'go',\n",
       " 'heartland',\n",
       " 'country',\n",
       " 'inn',\n",
       " 'www',\n",
       " 'com',\n",
       " 'outside',\n",
       " 'brenham',\n",
       " 'nice',\n",
       " 'place',\n",
       " '13',\n",
       " 'bedroom',\n",
       " '5',\n",
       " 'bedroom',\n",
       " 'house',\n",
       " 'side',\n",
       " 'side',\n",
       " 'country',\n",
       " 'real',\n",
       " 'relaxing',\n",
       " 'also',\n",
       " 'close',\n",
       " 'brenham',\n",
       " 'one',\n",
       " 'hour',\n",
       " '15',\n",
       " 'minutes',\n",
       " 'golf',\n",
       " 'shop',\n",
       " 'antique',\n",
       " 'craft',\n",
       " 'stores',\n",
       " 'brenham',\n",
       " 'eat',\n",
       " 'dinner',\n",
       " 'together',\n",
       " 'ranch',\n",
       " 'spend',\n",
       " 'time',\n",
       " 'meet',\n",
       " 'saturday',\n",
       " 'return',\n",
       " 'sunday',\n",
       " 'morning',\n",
       " 'like',\n",
       " 'done',\n",
       " 'past',\n",
       " 'second',\n",
       " 'option',\n",
       " 'would',\n",
       " 'stay',\n",
       " 'houston',\n",
       " 'dinner',\n",
       " 'together',\n",
       " 'nice',\n",
       " 'restaurant',\n",
       " 'dessert',\n",
       " 'time',\n",
       " 'visiting',\n",
       " 'recharging',\n",
       " 'one',\n",
       " 'homes',\n",
       " 'saturday',\n",
       " 'evening',\n",
       " 'might',\n",
       " 'easier',\n",
       " 'trade',\n",
       " 'would',\n",
       " 'much',\n",
       " 'time',\n",
       " 'together',\n",
       " 'let',\n",
       " 'decide',\n",
       " 'email',\n",
       " 'back',\n",
       " 'would',\n",
       " 'preference',\n",
       " 'course',\n",
       " 'available',\n",
       " 'weekend',\n",
       " 'democratic',\n",
       " 'process',\n",
       " 'prevail',\n",
       " 'majority',\n",
       " 'vote',\n",
       " 'rule',\n",
       " 'let',\n",
       " 'hear',\n",
       " 'soon',\n",
       " 'possible',\n",
       " 'preferably',\n",
       " 'end',\n",
       " 'weekend',\n",
       " 'vote',\n",
       " 'go',\n",
       " 'way',\n",
       " 'complaining',\n",
       " 'allowed',\n",
       " 'like',\n",
       " 'tend',\n",
       " 'great',\n",
       " 'weekend',\n",
       " 'great',\n",
       " 'golf',\n",
       " 'great',\n",
       " 'fishing',\n",
       " 'great',\n",
       " 'shopping',\n",
       " 'whatever',\n",
       " 'makes',\n",
       " 'happy',\n",
       " 'bobby']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails['clean_content'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomize the data\n",
    "randomized=emails.sample(frac=1,random_state=1)\n",
    "\n",
    "#Generate training set and test set\n",
    "train_set = randomized.iloc[:round(len(randomized) * 0.8)].reset_index(drop=True)\n",
    "test_set = randomized.iloc[round(len(randomized) * 0.8):].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "      <th>subjects</th>\n",
       "      <th>contents</th>\n",
       "      <th>clean_subject</th>\n",
       "      <th>clean_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: what the heck\\r\\ndaren ,\\r\\nnow what ...</td>\n",
       "      <td>0</td>\n",
       "      <td>what the heck</td>\n",
       "      <td>daren ,\\r\\nnow what ? i see ken is back and je...</td>\n",
       "      <td>[heck]</td>\n",
       "      <td>[daren, see, ken, back, jeff, development, jef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hilcorp old ocean volume\\r\\naccording...</td>\n",
       "      <td>0</td>\n",
       "      <td>hilcorp old ocean volume</td>\n",
       "      <td>according to gary hanks , we would like to hav...</td>\n",
       "      <td>[hilcorp, old, ocean, volume]</td>\n",
       "      <td>[according, gary, hanks, would, like, gas, val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: jurirne get latest softwares , 99 % s...</td>\n",
       "      <td>1</td>\n",
       "      <td>jurirne get latest softwares , 99 % savings ....</td>\n",
       "      <td>microsoft windows xp professional $ 50\\r\\nadob...</td>\n",
       "      <td>[jurirne, get, latest, softwares, 99, savings,...</td>\n",
       "      <td>[microsoft, windows, xp, professional, 50, ado...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: sitara patch\\r\\na patch is being rele...</td>\n",
       "      <td>0</td>\n",
       "      <td>sitara patch</td>\n",
       "      <td>a patch is being released to resolve a problem...</td>\n",
       "      <td>[sitara, patch]</td>\n",
       "      <td>[patch, released, resolve, problem, updates, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: archived great shots of california li...</td>\n",
       "      <td>1</td>\n",
       "      <td>archived great shots of california living</td>\n",
       "      <td>greetings love ,\\r\\nyour favourite celebs - re...</td>\n",
       "      <td>[archived, great, shots, california, living]</td>\n",
       "      <td>[greetings, love, favourite, celebs, revolting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: fw : why you shouldn ' t piss on the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>fw : why you shouldn ' t piss on the side of ...</td>\n",
       "      <td>- - - - - original message - - - - -\\r\\nfrom :...</td>\n",
       "      <td>[fw, piss, side, road]</td>\n",
       "      <td>[original, message, tcash, aimtech, net, mailt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: holiday invitation\\r\\nplease click on...</td>\n",
       "      <td>0</td>\n",
       "      <td>holiday invitation</td>\n",
       "      <td>please click on the attached link to launch yo...</td>\n",
       "      <td>[holiday, invitation]</td>\n",
       "      <td>[please, click, attached, link, launch, holida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4134</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: managing director and vice president ...</td>\n",
       "      <td>0</td>\n",
       "      <td>managing director and vice president elections</td>\n",
       "      <td>the managing director prc committee met this w...</td>\n",
       "      <td>[managing, director, vice, president, elections]</td>\n",
       "      <td>[managing, director, prc, committee, met, week...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4135</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: eastrans nom - 5 / 24 / 2000\\r\\nthis ...</td>\n",
       "      <td>0</td>\n",
       "      <td>eastrans nom - 5 / 24 / 2000</td>\n",
       "      <td>this is to nom 32 , 500 mmbtu into eastrans fo...</td>\n",
       "      <td>[eastrans, nom, 5, 24, 2000]</td>\n",
       "      <td>[nom, 32, 500, mmbtu, eastrans, 5, 24, 5, 23, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4136</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re :\\r\\ndaren ,\\r\\njust call me mike ...</td>\n",
       "      <td>0</td>\n",
       "      <td>re :</td>\n",
       "      <td>daren ,\\r\\njust call me mike .\\r\\nhow about th...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[daren, call, mike, thursday, 17, th, 1, 00, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4137 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  label_num  \\\n",
       "0      ham  Subject: what the heck\\r\\ndaren ,\\r\\nnow what ...          0   \n",
       "1      ham  Subject: hilcorp old ocean volume\\r\\naccording...          0   \n",
       "2     spam  Subject: jurirne get latest softwares , 99 % s...          1   \n",
       "3      ham  Subject: sitara patch\\r\\na patch is being rele...          0   \n",
       "4     spam  Subject: archived great shots of california li...          1   \n",
       "...    ...                                                ...        ...   \n",
       "4132   ham  Subject: fw : why you shouldn ' t piss on the ...          0   \n",
       "4133   ham  Subject: holiday invitation\\r\\nplease click on...          0   \n",
       "4134   ham  Subject: managing director and vice president ...          0   \n",
       "4135   ham  Subject: eastrans nom - 5 / 24 / 2000\\r\\nthis ...          0   \n",
       "4136   ham  Subject: re :\\r\\ndaren ,\\r\\njust call me mike ...          0   \n",
       "\n",
       "                                               subjects  \\\n",
       "0                                         what the heck   \n",
       "1                              hilcorp old ocean volume   \n",
       "2      jurirne get latest softwares , 99 % savings ....   \n",
       "3                                          sitara patch   \n",
       "4             archived great shots of california living   \n",
       "...                                                 ...   \n",
       "4132   fw : why you shouldn ' t piss on the side of ...   \n",
       "4133                                 holiday invitation   \n",
       "4134     managing director and vice president elections   \n",
       "4135                       eastrans nom - 5 / 24 / 2000   \n",
       "4136                                               re :   \n",
       "\n",
       "                                               contents  \\\n",
       "0     daren ,\\r\\nnow what ? i see ken is back and je...   \n",
       "1     according to gary hanks , we would like to hav...   \n",
       "2     microsoft windows xp professional $ 50\\r\\nadob...   \n",
       "3     a patch is being released to resolve a problem...   \n",
       "4     greetings love ,\\r\\nyour favourite celebs - re...   \n",
       "...                                                 ...   \n",
       "4132  - - - - - original message - - - - -\\r\\nfrom :...   \n",
       "4133  please click on the attached link to launch yo...   \n",
       "4134  the managing director prc committee met this w...   \n",
       "4135  this is to nom 32 , 500 mmbtu into eastrans fo...   \n",
       "4136  daren ,\\r\\njust call me mike .\\r\\nhow about th...   \n",
       "\n",
       "                                          clean_subject  \\\n",
       "0                                                [heck]   \n",
       "1                         [hilcorp, old, ocean, volume]   \n",
       "2     [jurirne, get, latest, softwares, 99, savings,...   \n",
       "3                                       [sitara, patch]   \n",
       "4          [archived, great, shots, california, living]   \n",
       "...                                                 ...   \n",
       "4132                             [fw, piss, side, road]   \n",
       "4133                              [holiday, invitation]   \n",
       "4134   [managing, director, vice, president, elections]   \n",
       "4135                       [eastrans, nom, 5, 24, 2000]   \n",
       "4136                                                 []   \n",
       "\n",
       "                                          clean_content  \n",
       "0     [daren, see, ken, back, jeff, development, jef...  \n",
       "1     [according, gary, hanks, would, like, gas, val...  \n",
       "2     [microsoft, windows, xp, professional, 50, ado...  \n",
       "3     [patch, released, resolve, problem, updates, p...  \n",
       "4     [greetings, love, favourite, celebs, revolting...  \n",
       "...                                                 ...  \n",
       "4132  [original, message, tcash, aimtech, net, mailt...  \n",
       "4133  [please, click, attached, link, launch, holida...  \n",
       "4134  [managing, director, prc, committee, met, week...  \n",
       "4135  [nom, 32, 500, mmbtu, eastrans, 5, 24, 5, 23, ...  \n",
       "4136  [daren, call, mike, thursday, 17, th, 1, 00, l...  \n",
       "\n",
       "[4137 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "      <th>subjects</th>\n",
       "      <th>contents</th>\n",
       "      <th>clean_subject</th>\n",
       "      <th>clean_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron / hpl actuals for june 15 , 200...</td>\n",
       "      <td>0</td>\n",
       "      <td>enron / hpl actuals for june 15 , 2000</td>\n",
       "      <td>teco tap 115 . 000 / hpl iferc ; 10 . 000 / en...</td>\n",
       "      <td>[enron, hpl, actuals, june, 15, 2000]</td>\n",
       "      <td>[teco, tap, 115, 000, hpl, iferc, 10, 000, enr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: anouncing a new player in the market ...</td>\n",
       "      <td>1</td>\n",
       "      <td>anouncing a new player in the market qbbcpryhrv</td>\n",
       "      <td>having trouble reading\\r\\nthis e - mail ? clic...</td>\n",
       "      <td>[anouncing, new, player, market, qbbcpryhrv]</td>\n",
       "      <td>[trouble, reading, e, mail, click, registratio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : republic royalty 5 / 00\\r\\ndone ...</td>\n",
       "      <td>0</td>\n",
       "      <td>re : republic royalty 5 / 00</td>\n",
       "      <td>done .\\r\\ndaren j farmer @ ect\\r\\n06 / 29 / 20...</td>\n",
       "      <td>[republic, royalty, 5, 00]</td>\n",
       "      <td>[done, daren, j, farmer, ect, 06, 29, 2000, 01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: instructions to remove spyware / adwa...</td>\n",
       "      <td>1</td>\n",
       "      <td>instructions to remove spyware / adware infec...</td>\n",
       "      <td>this message will inform you on how to remove ...</td>\n",
       "      <td>[instructions, remove, spyware, adware, infect...</td>\n",
       "      <td>[message, inform, remove, spyware, adware, pcs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: 90 % discounts on microsoft , adobe ,...</td>\n",
       "      <td>1</td>\n",
       "      <td>90 % discounts on microsoft , adobe , autodes...</td>\n",
       "      <td>microsoft windows xp professional 2002 $ 50 re...</td>\n",
       "      <td>[90, discounts, microsoft, adobe, autodesk, co...</td>\n",
       "      <td>[microsoft, windows, xp, professional, 2002, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: re [ 13 ]\\r\\ndriving at ? in 1876\\r\\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>re [ 13 ]</td>\n",
       "      <td>driving at ? in 1876\\r\\ndogs and cats that ' s...</td>\n",
       "      <td>[13]</td>\n",
       "      <td>[driving, 1876, dogs, cats, call, glrls, 9, ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: 29 th changes\\r\\n- - - - - - - - - - ...</td>\n",
       "      <td>0</td>\n",
       "      <td>29 th changes</td>\n",
       "      <td>- - - - - - - - - - - - - - - - - - - - - - fo...</td>\n",
       "      <td>[29, th, changes]</td>\n",
       "      <td>[forwarded, ami, chokshi, corp, enron, 02, 28,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: buy regalis , also known as superviag...</td>\n",
       "      <td>1</td>\n",
       "      <td>buy regalis , also known as superviagra or ci...</td>\n",
       "      <td>hi ,\\r\\nregalis , also known as superviagra or...</td>\n",
       "      <td>[buy, regalis, also, known, superviagra, cialis]</td>\n",
       "      <td>[hi, regalis, also, known, superviagra, cialis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: 24 x 5 products\\r\\nplease make sure t...</td>\n",
       "      <td>0</td>\n",
       "      <td>24 x 5 products</td>\n",
       "      <td>please make sure this is clearly understood by...</td>\n",
       "      <td>[24, x, 5, products]</td>\n",
       "      <td>[please, make, sure, clearly, understood, sche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: 5 th changes @ duke and air liquide\\r...</td>\n",
       "      <td>0</td>\n",
       "      <td>5 th changes @ duke and air liquide</td>\n",
       "      <td>- - - - - - - - - - - - - - - - - - - - - - fo...</td>\n",
       "      <td>[5, th, changes, duke, air, liquide]</td>\n",
       "      <td>[forwarded, ami, chokshi, corp, enron, 02, 04,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1034 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  label_num  \\\n",
       "0      ham  Subject: enron / hpl actuals for june 15 , 200...          0   \n",
       "1     spam  Subject: anouncing a new player in the market ...          1   \n",
       "2      ham  Subject: re : republic royalty 5 / 00\\r\\ndone ...          0   \n",
       "3     spam  Subject: instructions to remove spyware / adwa...          1   \n",
       "4     spam  Subject: 90 % discounts on microsoft , adobe ,...          1   \n",
       "...    ...                                                ...        ...   \n",
       "1029  spam  Subject: re [ 13 ]\\r\\ndriving at ? in 1876\\r\\n...          1   \n",
       "1030   ham  Subject: 29 th changes\\r\\n- - - - - - - - - - ...          0   \n",
       "1031  spam  Subject: buy regalis , also known as superviag...          1   \n",
       "1032   ham  Subject: 24 x 5 products\\r\\nplease make sure t...          0   \n",
       "1033   ham  Subject: 5 th changes @ duke and air liquide\\r...          0   \n",
       "\n",
       "                                               subjects  \\\n",
       "0                enron / hpl actuals for june 15 , 2000   \n",
       "1       anouncing a new player in the market qbbcpryhrv   \n",
       "2                          re : republic royalty 5 / 00   \n",
       "3      instructions to remove spyware / adware infec...   \n",
       "4      90 % discounts on microsoft , adobe , autodes...   \n",
       "...                                                 ...   \n",
       "1029                                          re [ 13 ]   \n",
       "1030                                      29 th changes   \n",
       "1031   buy regalis , also known as superviagra or ci...   \n",
       "1032                                    24 x 5 products   \n",
       "1033                5 th changes @ duke and air liquide   \n",
       "\n",
       "                                               contents  \\\n",
       "0     teco tap 115 . 000 / hpl iferc ; 10 . 000 / en...   \n",
       "1     having trouble reading\\r\\nthis e - mail ? clic...   \n",
       "2     done .\\r\\ndaren j farmer @ ect\\r\\n06 / 29 / 20...   \n",
       "3     this message will inform you on how to remove ...   \n",
       "4     microsoft windows xp professional 2002 $ 50 re...   \n",
       "...                                                 ...   \n",
       "1029  driving at ? in 1876\\r\\ndogs and cats that ' s...   \n",
       "1030  - - - - - - - - - - - - - - - - - - - - - - fo...   \n",
       "1031  hi ,\\r\\nregalis , also known as superviagra or...   \n",
       "1032  please make sure this is clearly understood by...   \n",
       "1033  - - - - - - - - - - - - - - - - - - - - - - fo...   \n",
       "\n",
       "                                          clean_subject  \\\n",
       "0                 [enron, hpl, actuals, june, 15, 2000]   \n",
       "1          [anouncing, new, player, market, qbbcpryhrv]   \n",
       "2                            [republic, royalty, 5, 00]   \n",
       "3     [instructions, remove, spyware, adware, infect...   \n",
       "4     [90, discounts, microsoft, adobe, autodesk, co...   \n",
       "...                                                 ...   \n",
       "1029                                               [13]   \n",
       "1030                                  [29, th, changes]   \n",
       "1031   [buy, regalis, also, known, superviagra, cialis]   \n",
       "1032                               [24, x, 5, products]   \n",
       "1033               [5, th, changes, duke, air, liquide]   \n",
       "\n",
       "                                          clean_content  \n",
       "0     [teco, tap, 115, 000, hpl, iferc, 10, 000, enr...  \n",
       "1     [trouble, reading, e, mail, click, registratio...  \n",
       "2     [done, daren, j, farmer, ect, 06, 29, 2000, 01...  \n",
       "3     [message, inform, remove, spyware, adware, pcs...  \n",
       "4     [microsoft, windows, xp, professional, 2002, 5...  \n",
       "...                                                 ...  \n",
       "1029  [driving, 1876, dogs, cats, call, glrls, 9, ho...  \n",
       "1030  [forwarded, ami, chokshi, corp, enron, 02, 28,...  \n",
       "1031  [hi, regalis, also, known, superviagra, cialis...  \n",
       "1032  [please, make, sure, clearly, understood, sche...  \n",
       "1033  [forwarded, ami, chokshi, corp, enron, 02, 04,...  \n",
       "\n",
       "[1034 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_vocabulary = []\n",
    "content_vocabulary = []\n",
    "\n",
    "for each_subject in train_set[\"clean_subject\"]:\n",
    "    for each_word in each_subject:\n",
    "        subject_vocabulary.append(each_word)\n",
    "\n",
    "for each_content in train_set[\"clean_content\"]:\n",
    "    for each_word in each_content:\n",
    "        content_vocabulary.append(each_word)\n",
    "    \n",
    "subject_vocabulary = list(set(subject_vocabulary))\n",
    "content_vocabulary = list(set(content_vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_word_count={each_word:[0]*len(train_set) for each_word in subject_vocabulary}\n",
    "content_word_count={each_word:[0]*len(train_set) for each_word in content_vocabulary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, email in enumerate(train_set[\"clean_subject\"]):\n",
    "    for each_word in email:\n",
    "        subject_word_count[each_word][index]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, email in enumerate(train_set[\"clean_content\"]):\n",
    "    for each_word in email:\n",
    "        content_word_count[each_word][index]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_subject = pd.DataFrame(subject_word_count)\n",
    "word_count_content = pd.DataFrame(content_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "closed                 31\n",
       "bandit                  2\n",
       "otcbb                  29\n",
       "8673849000404220545     1\n",
       "mainly                  5\n",
       "                       ..\n",
       "mgr                    10\n",
       "ecom                   29\n",
       "combustible             1\n",
       "2050                    2\n",
       "builds                  4\n",
       "Length: 43994, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_content.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_spam_subject = pd.concat([train_set[[\"clean_subject\",\"label\"]],word_count_subject],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ham_spam_subject = pd.concat([train_set[[\"label_num\"]],word_count_subject],axis=1)\n",
    "# ham_spam_content = pd.concat([train_set[[\"label_num\"]],word_count_content],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subject analysis\n",
    "spam_message = ham_spam_subject[ham_spam_subject[\"label\"]==\"spam\"]\n",
    "ham_message = ham_spam_subject[ham_spam_subject[\"label\"]==\"ham\"]\n",
    "p_spam = len(train_set[train_set[\"label\"]==\"spam\"])/len(train_set) \n",
    "p_ham = len(train_set[train_set[\"label\"]==\"ham\"])/len(train_set)\n",
    "alpha = 1\n",
    "total_subject_spam_words = spam_message.iloc[:,2:].sum(axis=0).sum() \n",
    "total_subject_ham_words = ham_message.iloc[:,2:].sum(axis=0).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Subject analysis\n",
    "# spam_message = ham_spam_subject[ham_spam_subject[\"label_num\"]==0]\n",
    "# ham_message = ham_spam_subject[ham_spam_subject[\"label_num\"]==1]\n",
    "# p_spam = len(train_set[train_set[\"label\"]==\"spam\"])/len(train_set) \n",
    "# p_ham = len(train_set[train_set[\"label\"]==\"ham\"])/len(train_set)\n",
    "# alpha = 1\n",
    "# total_subject_spam_words = spam_message.iloc[:,1:].sum(axis=0).sum() \n",
    "# total_subject_ham_words = ham_message.iloc[:,1:].sum(axis=0).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_subject</th>\n",
       "      <th>label</th>\n",
       "      <th>tutored</th>\n",
       "      <th>ferruginous</th>\n",
       "      <th>5593</th>\n",
       "      <th>cuts</th>\n",
       "      <th>owner</th>\n",
       "      <th>otcbb</th>\n",
       "      <th>odds</th>\n",
       "      <th>effectively</th>\n",
       "      <th>...</th>\n",
       "      <th>destination</th>\n",
       "      <th>care</th>\n",
       "      <th>gulf</th>\n",
       "      <th>contact</th>\n",
       "      <th>issued</th>\n",
       "      <th>james</th>\n",
       "      <th>mappings</th>\n",
       "      <th>connor</th>\n",
       "      <th>payroll</th>\n",
       "      <th>profiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[jurirne, get, latest, softwares, 99, savings,...</td>\n",
       "      <td>spam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[archived, great, shots, california, living]</td>\n",
       "      <td>spam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[]</td>\n",
       "      <td>spam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[duve, khumalo]</td>\n",
       "      <td>spam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[hot, wifes]</td>\n",
       "      <td>spam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4112</th>\n",
       "      <td>[hp, ink, cartridges, special]</td>\n",
       "      <td>spam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4115</th>\n",
       "      <td>[jim, come, watch]</td>\n",
       "      <td>spam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4127</th>\n",
       "      <td>[adult, chat, dating, profiles]</td>\n",
       "      <td>spam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4130</th>\n",
       "      <td>[personal, contact]</td>\n",
       "      <td>spam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4131</th>\n",
       "      <td>[viewsonic, airpanel, vl, 50, 15, inch, smart,...</td>\n",
       "      <td>spam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1211 rows × 4387 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_subject label  tutored  \\\n",
       "2     [jurirne, get, latest, softwares, 99, savings,...  spam        0   \n",
       "4          [archived, great, shots, california, living]  spam        0   \n",
       "9                                                    []  spam        0   \n",
       "11                                      [duve, khumalo]  spam        0   \n",
       "14                                         [hot, wifes]  spam        0   \n",
       "...                                                 ...   ...      ...   \n",
       "4112                     [hp, ink, cartridges, special]  spam        0   \n",
       "4115                                 [jim, come, watch]  spam        0   \n",
       "4127                    [adult, chat, dating, profiles]  spam        0   \n",
       "4130                                [personal, contact]  spam        0   \n",
       "4131  [viewsonic, airpanel, vl, 50, 15, inch, smart,...  spam        0   \n",
       "\n",
       "      ferruginous  5593  cuts  owner  otcbb  odds  effectively  ...  \\\n",
       "2               0     0     0      0      0     0            0  ...   \n",
       "4               0     0     0      0      0     0            0  ...   \n",
       "9               0     0     0      0      0     0            0  ...   \n",
       "11              0     0     0      0      0     0            0  ...   \n",
       "14              0     0     0      0      0     0            0  ...   \n",
       "...           ...   ...   ...    ...    ...   ...          ...  ...   \n",
       "4112            0     0     0      0      0     0            0  ...   \n",
       "4115            0     0     0      0      0     0            0  ...   \n",
       "4127            0     0     0      0      0     0            0  ...   \n",
       "4130            0     0     0      0      0     0            0  ...   \n",
       "4131            0     0     0      0      0     0            0  ...   \n",
       "\n",
       "      destination  care  gulf  contact  issued  james  mappings  connor  \\\n",
       "2               0     0     0        0       0      0         0       0   \n",
       "4               0     0     0        0       0      0         0       0   \n",
       "9               0     0     0        0       0      0         0       0   \n",
       "11              0     0     0        0       0      0         0       0   \n",
       "14              0     0     0        0       0      0         0       0   \n",
       "...           ...   ...   ...      ...     ...    ...       ...     ...   \n",
       "4112            0     0     0        0       0      0         0       0   \n",
       "4115            0     0     0        0       0      0         0       0   \n",
       "4127            0     0     0        0       0      0         0       0   \n",
       "4130            0     0     0        1       0      0         0       0   \n",
       "4131            0     0     0        0       0      0         0       0   \n",
       "\n",
       "      payroll  profiles  \n",
       "2           0         0  \n",
       "4           0         0  \n",
       "9           0         0  \n",
       "11          0         0  \n",
       "14          0         0  \n",
       "...       ...       ...  \n",
       "4112        0         0  \n",
       "4115        0         0  \n",
       "4127        0         1  \n",
       "4130        0         0  \n",
       "4131        0         0  \n",
       "\n",
       "[1211 rows x 4387 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_subject</th>\n",
       "      <th>label</th>\n",
       "      <th>tutored</th>\n",
       "      <th>ferruginous</th>\n",
       "      <th>5593</th>\n",
       "      <th>cuts</th>\n",
       "      <th>owner</th>\n",
       "      <th>otcbb</th>\n",
       "      <th>odds</th>\n",
       "      <th>effectively</th>\n",
       "      <th>...</th>\n",
       "      <th>destination</th>\n",
       "      <th>care</th>\n",
       "      <th>gulf</th>\n",
       "      <th>contact</th>\n",
       "      <th>issued</th>\n",
       "      <th>james</th>\n",
       "      <th>mappings</th>\n",
       "      <th>connor</th>\n",
       "      <th>payroll</th>\n",
       "      <th>profiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[heck]</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[hilcorp, old, ocean, volume]</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[sitara, patch]</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[hillarious]</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[devon]</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>[fw, piss, side, road]</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>[holiday, invitation]</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4134</th>\n",
       "      <td>[managing, director, vice, president, elections]</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4135</th>\n",
       "      <td>[eastrans, nom, 5, 24, 2000]</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4136</th>\n",
       "      <td>[]</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2926 rows × 4387 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_subject label  tutored  \\\n",
       "0                                               [heck]   ham        0   \n",
       "1                        [hilcorp, old, ocean, volume]   ham        0   \n",
       "3                                      [sitara, patch]   ham        0   \n",
       "5                                         [hillarious]   ham        0   \n",
       "6                                              [devon]   ham        0   \n",
       "...                                                ...   ...      ...   \n",
       "4132                            [fw, piss, side, road]   ham        0   \n",
       "4133                             [holiday, invitation]   ham        0   \n",
       "4134  [managing, director, vice, president, elections]   ham        0   \n",
       "4135                      [eastrans, nom, 5, 24, 2000]   ham        0   \n",
       "4136                                                []   ham        0   \n",
       "\n",
       "      ferruginous  5593  cuts  owner  otcbb  odds  effectively  ...  \\\n",
       "0               0     0     0      0      0     0            0  ...   \n",
       "1               0     0     0      0      0     0            0  ...   \n",
       "3               0     0     0      0      0     0            0  ...   \n",
       "5               0     0     0      0      0     0            0  ...   \n",
       "6               0     0     0      0      0     0            0  ...   \n",
       "...           ...   ...   ...    ...    ...   ...          ...  ...   \n",
       "4132            0     0     0      0      0     0            0  ...   \n",
       "4133            0     0     0      0      0     0            0  ...   \n",
       "4134            0     0     0      0      0     0            0  ...   \n",
       "4135            0     0     0      0      0     0            0  ...   \n",
       "4136            0     0     0      0      0     0            0  ...   \n",
       "\n",
       "      destination  care  gulf  contact  issued  james  mappings  connor  \\\n",
       "0               0     0     0        0       0      0         0       0   \n",
       "1               0     0     0        0       0      0         0       0   \n",
       "3               0     0     0        0       0      0         0       0   \n",
       "5               0     0     0        0       0      0         0       0   \n",
       "6               0     0     0        0       0      0         0       0   \n",
       "...           ...   ...   ...      ...     ...    ...       ...     ...   \n",
       "4132            0     0     0        0       0      0         0       0   \n",
       "4133            0     0     0        0       0      0         0       0   \n",
       "4134            0     0     0        0       0      0         0       0   \n",
       "4135            0     0     0        0       0      0         0       0   \n",
       "4136            0     0     0        0       0      0         0       0   \n",
       "\n",
       "      payroll  profiles  \n",
       "0           0         0  \n",
       "1           0         0  \n",
       "3           0         0  \n",
       "5           0         0  \n",
       "6           0         0  \n",
       "...       ...       ...  \n",
       "4132        0         0  \n",
       "4133        0         0  \n",
       "4134        0         0  \n",
       "4135        0         0  \n",
       "4136        0         0  \n",
       "\n",
       "[2926 rows x 4387 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5753, 12823)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_subject_spam_words,total_subject_ham_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spam_probability = p_spam\n",
    "# ham_probability = p_ham\n",
    "# new_list=\n",
    "# for each_word in new_list:\n",
    "#     if str(each_word) in subject_vocabulary:\n",
    "#         each_word_spam_prob = (spam_message[each_word].sum()+1)/(total_subject_spam_words+subject_vocab_length)\n",
    "#         spam_probability*=each_word_spam_prob\n",
    "            \n",
    "#         each_word_ham_prob = (ham_message[each_word].sum()+1)/(total_subject_ham_words+subject_vocab_length)\n",
    "#         ham_probability*=each_word_ham_prob\n",
    "        \n",
    "#     if ham_probability > spam_probability:\n",
    "#         predictions.append(\"ham\")\n",
    "#     elif ham_probability < spam_probability:\n",
    "#         predictions.append(\"spam\")\n",
    "#     else:\n",
    "#         predictions.append(\"classification required\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_subject = test_set.copy()\n",
    "\n",
    "predictions=[]\n",
    "subject_vocab_length = len(subject_vocabulary)\n",
    "\n",
    "for each_subject in test_set_subject[\"clean_subject\"]:\n",
    "    spam_probability = p_spam\n",
    "    ham_probability = p_ham\n",
    "    for each_word in each_subject:\n",
    "        if each_word in subject_vocabulary:\n",
    "            each_word_spam_prob = (spam_message[each_word].sum()+alpha)/(total_subject_spam_words+alpha*subject_vocab_length)\n",
    "            spam_probability*=each_word_spam_prob\n",
    "            \n",
    "            each_word_ham_prob = (ham_message[each_word].sum()+alpha)/(total_subject_ham_words+alpha*subject_vocab_length)\n",
    "            ham_probability*=each_word_ham_prob\n",
    "        \n",
    "    if ham_probability > spam_probability:\n",
    "        predictions.append(\"ham\")\n",
    "    elif ham_probability < spam_probability:\n",
    "        predictions.append(\"spam\")\n",
    "    else:\n",
    "        predictions.append(\"classification required\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['message', 'subject']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_subject[\"clean_subject\"].iloc[768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_message[\"ejaculation\"].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def classify(detail,vocabulary):\n",
    "#     spam_probability = p_spam\n",
    "#     ham_probability = p_ham\n",
    "#     for each_detail in detail:\n",
    "#         if each_word in vocabulary:\n",
    "#             each_word_spam_prob = (spam_message[each_word].sum(axis=0)+alpha)/(total_subject_spam_words+alpha*subject_vocab_length)\n",
    "#             spam_probability*=each_word_spam_prob\n",
    "            \n",
    "#             each_word_ham_prob = (ham_message[each_word].sum(axis=0)+alpha)/(total_subject_ham_words+alpha*subject_vocab_length)\n",
    "#             ham_probability*=each_word_ham_prob\n",
    "        \n",
    "#     if ham_probability > spam_probability:\n",
    "#         predictions.append(\"ham\")\n",
    "#     elif ham_probability < spam_probability:\n",
    "#         predictions.append(\"spam\")\n",
    "#     else:\n",
    "#         predictions.append(\"classification required\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_subject[\"predictions\"] = pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham                        0.773694\n",
       "spam                       0.225338\n",
       "classification required    0.000967\n",
       "Name: predictions, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_subject[\"predictions\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.2321083172147"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_set_subject[\"predictions\"] == test_set_subject[\"label\"]).sum()/len(test_set_subject)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_set_subject[\"predictions\"] != test_set_subject[\"label\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Content analysis\n",
    "ham_spam_content = pd.concat([train_set[\"label_num\"],word_count_content],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_num</th>\n",
       "      <th>closed</th>\n",
       "      <th>bandit</th>\n",
       "      <th>otcbb</th>\n",
       "      <th>8673849000404220545</th>\n",
       "      <th>mainly</th>\n",
       "      <th>dmco</th>\n",
       "      <th>finale</th>\n",
       "      <th>barny</th>\n",
       "      <th>bilder</th>\n",
       "      <th>...</th>\n",
       "      <th>6517</th>\n",
       "      <th>rangoon</th>\n",
       "      <th>italy</th>\n",
       "      <th>spiffing</th>\n",
       "      <th>gulf</th>\n",
       "      <th>mgr</th>\n",
       "      <th>ecom</th>\n",
       "      <th>combustible</th>\n",
       "      <th>2050</th>\n",
       "      <th>builds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 43995 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label_num  closed  bandit  otcbb  8673849000404220545  mainly  dmco  \\\n",
       "0           0       0       0      0                    0       0     0   \n",
       "1           0       0       0      0                    0       0     0   \n",
       "3           0       0       0      0                    0       0     0   \n",
       "5           0       0       0      0                    0       0     0   \n",
       "6           0       0       0      0                    0       0     0   \n",
       "7           0       0       0      0                    0       0     0   \n",
       "8           0       0       0      0                    0       0     0   \n",
       "10          0       0       0      0                    0       0     0   \n",
       "12          0       0       0      0                    0       0     0   \n",
       "13          0       0       0      0                    0       0     0   \n",
       "\n",
       "    finale  barny  bilder  ...  6517  rangoon  italy  spiffing  gulf  mgr  \\\n",
       "0        0      0       0  ...     0        0      0         0     0    0   \n",
       "1        0      0       0  ...     0        0      0         0     0    0   \n",
       "3        0      0       0  ...     0        0      0         0     0    0   \n",
       "5        0      0       0  ...     0        0      0         0     0    0   \n",
       "6        0      0       0  ...     0        0      0         0     0    0   \n",
       "7        0      0       0  ...     0        0      0         0     0    0   \n",
       "8        0      0       0  ...     0        0      0         0     0    0   \n",
       "10       0      0       0  ...     0        0      0         0     0    0   \n",
       "12       0      0       0  ...     0        0      0         0     0    0   \n",
       "13       0      0       0  ...     0        0      0         0     0    0   \n",
       "\n",
       "    ecom  combustible  2050  builds  \n",
       "0      0            0     0       0  \n",
       "1      0            0     0       0  \n",
       "3      0            0     0       0  \n",
       "5      0            0     0       0  \n",
       "6      0            0     0       0  \n",
       "7      0            0     0       0  \n",
       "8      0            0     0       0  \n",
       "10     0            0     0       0  \n",
       "12     0            0     0       0  \n",
       "13     0            0     0       0  \n",
       "\n",
       "[10 rows x 43995 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_spam_content[ham_spam_content[\"label_num\"]==0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Content analysis\n",
    "spam_message = ham_spam_content[ham_spam_content[\"label_num\"]==1]\n",
    "ham_message = ham_spam_content[ham_spam_content[\"label_num\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_content_spam_words = spam_message.iloc[:,1:].sum(axis=0).sum() \n",
    "total_content_ham_words = ham_message.iloc[:,1:].sum(axis=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_content = test_set.copy()\n",
    "\n",
    "predictions=[]\n",
    "content_vocab_length = len(content_vocabulary)\n",
    "\n",
    "for each_content in test_set_content[\"clean_content\"]:\n",
    "    spam_probability = p_spam\n",
    "    ham_probability = p_ham\n",
    "    for each_word in each_content:\n",
    "        if each_word in content_vocabulary:\n",
    "            each_word_spam_prob = (spam_message[each_word].sum(axis=0)+alpha)/(total_content_spam_words+alpha*content_vocab_length)\n",
    "            spam_probability*=each_word_spam_prob\n",
    "            \n",
    "            each_word_ham_prob = (ham_message[each_word].sum(axis=0)+alpha)/(total_content_ham_words+alpha*content_vocab_length)\n",
    "            ham_probability*=each_word_ham_prob\n",
    "        \n",
    "    if ham_probability > spam_probability:\n",
    "        predictions.append(0)\n",
    "    elif ham_probability < spam_probability:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    52.804642\n",
       "5    29.497099\n",
       "1    17.698259\n",
       "Name: predictions, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_content[\"predictions\"] = pd.Series(predictions)\n",
    "test_set_content[\"predictions\"].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.60154738878144"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_set_content[\"predictions\"] == test_set_content[\"label_num\"]).sum()/len(test_set_content)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_content[\"predictions\"]==5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_num</th>\n",
       "      <th>subjects</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>enron methanol ; meter # : 988291</td>\n",
       "      <td>this is a follow up to the note i gave you on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>hpl nom for january 9 , 2001</td>\n",
       "      <td>( see attached file : hplnol 09 . xls )\\r\\n- h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>neon retreat</td>\n",
       "      <td>ho ho ho , we ' re around to that most wonderf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>photoshop , windows , office . cheap . main t...</td>\n",
       "      <td>abasements darer prudently fortuitous undergon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>re : indian springs</td>\n",
       "      <td>this deal is to book the teco pvr revenue . it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>0</td>\n",
       "      <td>put the 10 on the ft</td>\n",
       "      <td>the transport volumes decreased from 25000 to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>0</td>\n",
       "      <td>3 / 4 / 2000 and following noms</td>\n",
       "      <td>hpl can ' t take the extra 15 mmcf / d over th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>0</td>\n",
       "      <td>calpine daily gas nomination</td>\n",
       "      <td>&gt;\\r\\n&gt;\\r\\njulie , as i mention earlier we hope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>0</td>\n",
       "      <td>industrial worksheets for august 2000 activity</td>\n",
       "      <td>attached are the worksheets for august 2000 ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>1</td>\n",
       "      <td>important online banking alert</td>\n",
       "      <td>dear valued citizensr bank member ,\\r\\ndue to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5171 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label_num                                           subjects  \\\n",
       "0             0                  enron methanol ; meter # : 988291   \n",
       "1             0                       hpl nom for january 9 , 2001   \n",
       "2             0                                       neon retreat   \n",
       "3             1   photoshop , windows , office . cheap . main t...   \n",
       "4             0                                re : indian springs   \n",
       "...         ...                                                ...   \n",
       "5166          0                               put the 10 on the ft   \n",
       "5167          0                    3 / 4 / 2000 and following noms   \n",
       "5168          0                       calpine daily gas nomination   \n",
       "5169          0     industrial worksheets for august 2000 activity   \n",
       "5170          1                     important online banking alert   \n",
       "\n",
       "                                               contents  \n",
       "0     this is a follow up to the note i gave you on ...  \n",
       "1     ( see attached file : hplnol 09 . xls )\\r\\n- h...  \n",
       "2     ho ho ho , we ' re around to that most wonderf...  \n",
       "3     abasements darer prudently fortuitous undergon...  \n",
       "4     this deal is to book the teco pvr revenue . it...  \n",
       "...                                                 ...  \n",
       "5166  the transport volumes decreased from 25000 to ...  \n",
       "5167  hpl can ' t take the extra 15 mmcf / d over th...  \n",
       "5168  >\\r\\n>\\r\\njulie , as i mention earlier we hope...  \n",
       "5169  attached are the worksheets for august 2000 ac...  \n",
       "5170  dear valued citizensr bank member ,\\r\\ndue to ...  \n",
       "\n",
       "[5171 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails[[\"label_num\",\"subjects\",\"contents\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instrusctions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase=True,stop_words=\"english\")\n",
    "subject_vectorized = vectorizer.fit_transform(emails[\"subjects\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_subject, test_subject, train_ham_spam, test_ham_spam = train_test_split(subject_vectorized,\n",
    "                                                                              emails[\"label_num\"],\n",
    "                                                                              test_size=0.2,\n",
    "                                                                              random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "subject_model = LogisticRegression()\n",
    "subject_model.fit(train_subject, train_ham_spam)\n",
    "predictions = subject_model.predict(test_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9072463768115943"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_ham_spam,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic contents\n",
    "emails[\"contents\"] = emails[\"contents\"].str.replace(\"\\r\\n\",' ')\n",
    "content_vectorized = vectorizer.fit_transform(emails[\"contents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_content, test_content, train_ham_spam, test_ham_spam = train_test_split(content_vectorized,\n",
    "                                                                              emails[\"label_num\"],\n",
    "                                                                              test_size=0.2,\n",
    "                                                                              random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9922705314009662"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "content_model = LogisticRegression()\n",
    "content_model.fit(train_content, train_ham_spam)\n",
    "predictions = content_model.predict(test_content)\n",
    "accuracy_score(test_ham_spam,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instructions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://towardsdatascience.com/natural-language-processing-feature-engineering-using-tf-idf-e8b9d00e7e76\n",
    "- https://towardsdatascience.com/spam-detection-with-logistic-regression-23e3709e522\n",
    "- https://www.analyticsvidhya.com/blog/2021/07/deep-understanding-of-discriminative-and-generative-models-in-machine-learning/\n",
    "- https://medium.com/@sangha_deb/naive-bayes-vs-logistic-regression-a319b07a5d4c\n",
    "- https://towardsdatascience.com/machine-learning-and-charity-donations-a-case-study-ed6e63f18db7\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "- https://kavita-ganesan.com/tfidftransformer-tfidfvectorizer-usage-differences/#.Ya3vVbrhXDc\n",
    "- https://stackoverflow.com/questions/9535954/printing-lists-as-tabular-data\n",
    "- https://www.cs.dartmouth.edu/~deepc/Courses/W20/lecs/lec15supp.pdf\n",
    "- https://stackoverflow.com/questions/5658369/how-to-input-a-regex-in-string-replace\n",
    "#pip install BeautifulTable\n",
    "#pip install termcolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instructions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instructions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instructions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instructions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instructions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instructions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instructions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instructions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instructions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
